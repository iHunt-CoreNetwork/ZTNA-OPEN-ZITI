"use strict";(self.webpackChunkopen_ziti=self.webpackChunkopen_ziti||[]).push([[8911],{3905:(e,t,i)=>{i.d(t,{Zo:()=>d,kt:()=>m});var n=i(67294);function o(e,t,i){return t in e?Object.defineProperty(e,t,{value:i,enumerable:!0,configurable:!0,writable:!0}):e[t]=i,e}function r(e,t){var i=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),i.push.apply(i,n)}return i}function a(e){for(var t=1;t<arguments.length;t++){var i=null!=arguments[t]?arguments[t]:{};t%2?r(Object(i),!0).forEach((function(t){o(e,t,i[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(i)):r(Object(i)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(i,t))}))}return e}function l(e,t){if(null==e)return{};var i,n,o=function(e,t){if(null==e)return{};var i,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)i=r[n],t.indexOf(i)>=0||(o[i]=e[i]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)i=r[n],t.indexOf(i)>=0||Object.prototype.propertyIsEnumerable.call(e,i)&&(o[i]=e[i])}return o}var s=n.createContext({}),c=function(e){var t=n.useContext(s),i=t;return e&&(i="function"==typeof e?e(t):a(a({},t),e)),i},d=function(e){var t=c(e.components);return n.createElement(s.Provider,{value:t},e.children)},h="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var i=e.components,o=e.mdxType,r=e.originalType,s=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),h=c(i),u=o,m=h["".concat(s,".").concat(u)]||h[u]||p[u]||r;return i?n.createElement(m,a(a({ref:t},d),{},{components:i})):n.createElement(m,a({ref:t},d))}));function m(e,t){var i=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=i.length,a=new Array(r);a[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[h]="string"==typeof e?e:o,a[1]=l;for(var c=2;c<r;c++)a[c]=i[c];return n.createElement.apply(null,a)}return n.createElement.apply(null,i)}u.displayName="MDXCreateElement"},64324:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>s,contentTitle:()=>a,default:()=>p,frontMatter:()=>r,metadata:()=>l,toc:()=>c});var n=i(87462),o=(i(67294),i(3905));const r={authors:"dovholuknf"},a="Configuring OpenZiti to Enable Prometheus",l={permalink:"/blog/zitification/prometheus/part2",source:"@site/blog/zitification/prometheus/part2.md",title:"Configuring OpenZiti to Enable Prometheus",description:"_This is part two of a three-part article. This article provides the technical deep dive into the steps necessary to implement the vision",date:"2024-01-29T15:45:34.000Z",formattedDate:"January 29, 2024",tags:[],readingTime:19.14,hasTruncateMarker:!1,authors:[{name:"Clint Dovholuk",title:"OpenZiti Maintainer",url:"https://github.com/dovholuknf",imageURL:"https://avatars.githubusercontent.com/u/46322585?v=4",key:"dovholuknf"}],frontMatter:{authors:"dovholuknf"},prevItem:{title:"Enable Prometheus to Scrape Anything from Anywhere",permalink:"/blog/zitification/prometheus/part1"},nextItem:{title:"Scraping Anything, Anywhere in Action",permalink:"/blog/zitification/prometheus/part3"}},s={authorsImageUrls:[void 0]},c=[{value:"Goals",id:"goals",level:2},{value:"Zitified Prometheus",id:"zitified-prometheus",level:2},{value:"Solution Overview",id:"solution-overview",level:2},{value:"Digging In",id:"digging-in",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"ClusterA - Using <code>ziti-host</code>",id:"clustera---using-ziti-host",level:2},{value:"Pod 1 - <code>ziti-host</code>",id:"pod-1---ziti-host",level:3},{value:"Create the Identity",id:"create-the-identity",level:4},{value:"Deploy <code>ziti-host</code> into ClusterA",id:"deploy-ziti-host-into-clustera",level:4},{value:"Pod 2 - <code>reflectz</code>",id:"pod-2---reflectz",level:3},{value:"Create and Enroll the Identity",id:"create-and-enroll-the-identity",level:4},{value:"Create Configs and Services (including Tunneling-based Access)",id:"create-configs-and-services-including-tunneling-based-access",level:4},{value:"Authorize the Workload and Clients",id:"authorize-the-workload-and-clients",level:4},{value:"Deploy <code>reflectz</code>",id:"deploy-reflectz",level:4},{value:"Pod 3 - <code>Prometheuz</code>",id:"pod-3---prometheuz",level:3},{value:"Overlay Work - Setting Up OpenZiti",id:"overlay-work---setting-up-openziti",level:4},{value:"Create and Enroll the Identity",id:"create-and-enroll-the-identity-1",level:4},{value:"Create Configs and Services (including Tunneling-based Access)",id:"create-configs-and-services-including-tunneling-based-access-1",level:4},{value:"Authorize the Workload and Clients",id:"authorize-the-workload-and-clients-1",level:4},{value:"Deploying <code>Prometheuz</code>",id:"deploying-prometheuz-1",level:4},{value:"ClusterB - Fully Dark",id:"clusterb---fully-dark",level:2},{value:"Pod1 - <code>reflectz</code>",id:"pod1---reflectz",level:3},{value:"Create the Identity",id:"create-the-identity-1",level:4},{value:"Create Configs and Services (including Tunneling-based Access)",id:"create-configs-and-services-including-tunneling-based-access-2",level:4},{value:"Authorize the Workload to Bind the Services",id:"authorize-the-workload-to-bind-the-services",level:4},{value:"Authorize Clients to Access the Services",id:"authorize-clients-to-access-the-services",level:4},{value:"Deploy <code>reflectz</code>",id:"deploy-reflectz-1",level:4},{value:"Pod 2 - <code>Prometheuz</code>",id:"pod-2---prometheuz",level:3},{value:"Create the Identity",id:"create-the-identity-2",level:4},{value:"Create <strong>One</strong> Config and Service",id:"create-one-config-and-service",level:4},{value:"Authorize Clients and Prometheus to Bind the Service",id:"authorize-clients-and-prometheus-to-bind-the-service",level:4},{value:"Deploying <code>Prometheuz</code>",id:"deploying-prometheuz",level:4},{value:"What&#39;s Next",id:"whats-next",level:2},{value:"Addendum - a Quicker Start",id:"addendum---a-quicker-start",level:4}],d={toc:c},h="wrapper";function p(e){let{components:t,...r}=e;return(0,o.kt)(h,(0,n.Z)({},d,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},"This is part two of a three-part article. This article provides the technical deep dive into the steps necessary to implement the vision\noutlined in ",(0,o.kt)("a",{parentName:"em",href:"/blog/zitification/prometheus/part1"},"part one"),". This article will be heavy on OpenZiti CLI commands, explaining what we are doing to configure the\noverlay network, and why. In ",(0,o.kt)("a",{parentName:"em",href:"/blog/zitification/prometheus/part3"},"the final article"),", we will explore what we have just created and understand what was just\ncreated")),(0,o.kt)("hr",null),(0,o.kt)("h2",{id:"goals"},"Goals"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Incredibly easy to deploy Prometheus servers"),(0,o.kt)("li",{parentName:"ul"},"No ports exposed to the internet"),(0,o.kt)("li",{parentName:"ul"},"Prometheus servers can be deployed listening on the overlay, not on the underlay"),(0,o.kt)("li",{parentName:"ul"},"Private Kubernetes API")),(0,o.kt)("h2",{id:"zitified-prometheus"},"Zitified Prometheus"),(0,o.kt)("p",null,"As described in ",(0,o.kt)("a",{parentName:"p",href:"/blog/zitification/prometheus/part1"},"the previous article"),", Prometheus really prefers to be able to gather metrics from the targets it is\nmonitoring. When the target is behind a firewall, you will be left with two choices.\n",(0,o.kt)("img",{parentName:"p",src:"https://github.com/openziti/branding/raw/main/images/ziggy/svg/Ziggy%20The%20Superhero.svg",alt:"superhero"}),"\nYou can choose to open a hole in the firewall granting access (a generally bad idea), or you can use a PushGateway. Even if you choose to\nuse the PushGateway, Prometheus will still need to be able to access and pull from the PushGateway so you'll still need some port open and\nlistening for Prometheus to collect data."),(0,o.kt)("p",null,"What we really want is to enable Prometheus to scrape data from targets without needing to expose any ports to the internet. It would be ",(0,o.kt)("strong",{parentName:"p"},"\neven better"),' if we didn\'t have to expose any ports at all, even to the local "trusted" network. This capability is something that is\nunique to an OpenZiti-enabled application. You can take an OpenZiti SDK and embed it into your application, and give your app zero trust\nsuperpowers! If we take an OpenZiti SDK and embed it into Prometheus, we can give Prometheus the superpower of invisibility and\naddressability. Embedding an OpenZiti SDK produces a ',(0,o.kt)("a",{parentName:"p",href:"/blog/zitification"},"zitified")," version of Prometheus. With an\nOpenZiti-powered Prometheus, no ports need to be open."),(0,o.kt)("p",null,"The OpenZiti project has done the work to produce an OpenZiti-enabled version of Prometheus. It's also entirely open source. Check it out\nfrom the OpenZiti Test Kitchen hosted on GitHub ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/openziti-test-kitchen/prometheus"},"https://github.com/openziti-test-kitchen/prometheus"),"."),(0,o.kt)("h2",{id:"solution-overview"},"Solution Overview"),(0,o.kt)("p",null,"As you'll recall from ",(0,o.kt)("a",{parentName:"p",href:"/blog/zitification/prometheus/part1"},"part1"),', we are trying to use Prometheus to monitor workloads in two different\nKubernetes clusters. We are going to deploy one cluster which will represent a first step of an OpenZiti solution.\nIt will use a Prometheus sever which is OpenZiti-enabled, but it will still listen on the underlay network and be\navailable to local devices on an ip:port. This Prometheus server will use OpenZiti to scrape targets which\nare available anywhere on the OpenZiti overlay network and we\'ll refer to this as "ClusterA".'),(0,o.kt)("p",null,"We'll also deploy a second OpenZiti-enabled Prometheus server, in a totally separate Kubernetes cluster. This\nPrometheus server will ",(0,o.kt)("strong",{parentName:"p"},"not"),' listen on an ip:port. Instead, it will listen exclusively on the OpenZiti overlay.\nThis Prometheus server will have no ports available to attack and will only be accessible via a properly authorized\nand authenticated OpenZiti client. This will be our "ClusterB"'),(0,o.kt)("p",null,"Finally, we'll stand up a third Prometheus server and use it to federate metrics back to a \"central\" Prometheus\nserver. This emulates what one might do to provide a central location for humans to go to in order to visualize data\nor use the Prometheus server. We won't care where this is deployed, we'll actually deploy it in locally and then\nmove it to a private server in AWS just to show how easy it that is. "),(0,o.kt)("p",null,"This is what the solution we'll build looks like:\n",(0,o.kt)("img",{alt:"after",src:i(81283).Z,width:"1264",height:"531"})),(0,o.kt)("hr",null),(0,o.kt)("h2",{id:"digging-in"},"Digging In"),(0,o.kt)("p",null,"Let's get to work and build this solution. We'll need some legwork done first. "),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"[!NOTE]","\nIt's going to get deep in this article with CLI commands. You'll see what the OpenZiti objects are that get created and learn why.\nYou might not want to replicate the solution on your own and instead are looking for \"the big reveal\". If that describes you, just\nskim this article lightly and get on to ",(0,o.kt)("a",{parentName:"p",href:"/blog/zitification/prometheus/part3"},"part3"),". In part 3 we'll explore the deployed solution and see what makes it so\ninteresting and cool.")),(0,o.kt)("h3",{id:"prerequisites"},"Prerequisites"),(0,o.kt)("p",null,(0,o.kt)("img",{parentName:"p",src:"https://github.com/openziti/branding/raw/main/images/ziggy/svg/Ziggy%20The%20Construction%20Worker.svg",alt:"construction worker"})),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"You have an OpenZiti overlay network available. If not, for this scenario you will want to use\n",(0,o.kt)("a",{parentName:"li",href:"/docs/learn/quickstarts/network/hosted"},'"host your own"'),". You'll also want to have the ziti cli tool on your path"),(0,o.kt)("li",{parentName:"ul"},"Two Kubernetes clusters provisioned"),(0,o.kt)("li",{parentName:"ul"},"Necessary tooling installed and available on the path",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"kubectl"),(0,o.kt)("li",{parentName:"ul"},"helm"))),(0,o.kt)("li",{parentName:"ul"},"bash/zsh shell - tested in bash and some commands will use variables. If you use another shell, change accordingly"),(0,o.kt)("li",{parentName:"ul"},"a machine with ",(0,o.kt)("a",{parentName:"li",href:"https://docs.docker.com/get-docker/"},"docker installed")," to run the final Prometheus sever on (your local machine is fine)"),(0,o.kt)("li",{parentName:"ul"},"Ziti Desktop Edge installed on the development machine. I use\n",(0,o.kt)("a",{parentName:"li",href:"https://github.com/openziti/desktop-edge-win/releases/latest/"},"Ziti Desktop Edge for Windows"),"."),(0,o.kt)("li",{parentName:"ul"},"A temporary folder exists to house files as we need them: /tmp/prometheus")),(0,o.kt)("hr",null),(0,o.kt)("h2",{id:"clustera---using-ziti-host"},"ClusterA - Using ",(0,o.kt)("inlineCode",{parentName:"h2"},"ziti-host")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"clusterA",src:i(13).Z,width:"349",height:"505"})),(0,o.kt)("p",null,"We start with an empty OpenZiti network, and two empty Kubernetes clusters. Let's start by populating ClusterA. We will deploy three\npods into this Kubernetes cluster. When done, the Kubernetes cluster will look similar to the image to the right."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Pod 1. ",(0,o.kt)("strong",{parentName:"li"},"ziti-host"),". This pod will provide what is effectively the equivalent of a Kubernetes ingress controller. We'll install this\nusing helm from a NetFoundry provided chart"),(0,o.kt)("li",{parentName:"ul"},"Pod 2. ",(0,o.kt)("strong",{parentName:"li"},"prometheuz"),". This pod will be our Prometheus server with OpenZiti embedded in it. We won't use OpenZiti to listen on the\noverlay network. Instead, we will follow a more traditional model of listening on the underlay at a known ip:port combination. We'll\ninstall this pod using a chart from the OpenZiti charts repository."),(0,o.kt)("li",{parentName:"ul"},"Pod 3. ",(0,o.kt)("strong",{parentName:"li"},"reflectz"),". This pod represents the workload which we want to monitor. This is another chart provided by the OpenZiti chart\nrepository and will also be installed with helm. If you are interested in viewing the source code for this project you can find it on\n",(0,o.kt)("a",{parentName:"li",href:"https://github.com/nf-npieros/sdk-golang/tree/feature/reflect-prometheus"},"GitHub here"))),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"[!NOTE]",'\nRunning the ziti cli commands shown below as shown will expect you to have the ziti binary on your path. Also it is expected that all\nthe commands run will run from the same "development" machine with the expected tools available. Reach out on discourse if you get stuck.')),(0,o.kt)("h3",{id:"pod-1---ziti-host"},"Pod 1 - ",(0,o.kt)("inlineCode",{parentName:"h3"},"ziti-host")),(0,o.kt)("p",null,'We will start off deploying Pod 1, ziti-host, to provide access to Kubernetes ClusterA.  The ziti-host pod will require a single\nidentity to be provisioned. We will use a shortened name for the cluster and we\'ll embed that name into the identity to make it easier\nfor us to understand what identity we provisioned and why, should we ever need to reference these identities later.  We\'ll refer to\nClusterA as simply "kubeA". Let\'s make the identity now. Notice we are also passing the "-a" attribute during creation to add a role\nattribute to the identity of ',(0,o.kt)("inlineCode",{parentName:"p"},"kubeA.services"),". This will be used later when setting up policies."),(0,o.kt)("h4",{id:"create-the-identity"},"Create the Identity"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},'ziti edge create identity device kubeA.ziti.id -o /tmp/prometheus/kubeA.ziti.id.jwt -a "kubeA.services"\n')),(0,o.kt)("p",null,"You should see confirmation output such as:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},"New identity kubeA.ziti.id created with id: BeyyFUZFDR\nEnrollment expires at 2022-04-22T01:18:53.402Z\n")),(0,o.kt)("h4",{id:"deploy-ziti-host-into-clustera"},"Deploy ",(0,o.kt)("inlineCode",{parentName:"h4"},"ziti-host")," into ClusterA"),(0,o.kt)("p",null,"Once created, we can use helm to install the ",(0,o.kt)("inlineCode",{parentName:"p"},"ziti-host")," pod. The jwt is a one-use token and will be useless after being consumed by\n",(0,o.kt)("inlineCode",{parentName:"p"},"ziti-host"),". As this is probably your first time running this helm chart, you will need to install it. The command is idempotent to\nrunning it over and over is of no concern. Run the following:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},'helm repo add netfoundry https://netfoundry.github.io/charts/\nhelm repo update\nhelm install ziti-host netfoundry/ziti-host --set-file enrollmentToken="/tmp/prometheus/kubeA.ziti.id.jwt"\n')),(0,o.kt)("p",null,"You will see the confirmation output from helm. Now when you look at your Kubernetes cluster with ",(0,o.kt)("inlineCode",{parentName:"p"},"kubectl"),", you will see a pod deployed:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},"kubectl get pods\nNAME                        READY   STATUS    RESTARTS   AGE\nziti-host-db55b5c4b-rpc7f   1/1     Running   0          2m40s\n")),(0,o.kt)("p",null,"Awesome, we have our first deployed pod. It's useless at the moment as we have defined no services, nor authorized any services. Right\nnow there's nothing to connect to, so we can simply move on and install the next pod, ",(0,o.kt)("inlineCode",{parentName:"p"},"reflectz"),"."),(0,o.kt)("h3",{id:"pod-2---reflectz"},"Pod 2 - ",(0,o.kt)("inlineCode",{parentName:"h3"},"reflectz")),(0,o.kt)("p",null,"The first pod we want to have access to is the ",(0,o.kt)("inlineCode",{parentName:"p"},"reflectz")," pod. It is a workload we will deploy that will do two things. First, it will\nlisten on the OpenZiti overlay network for connections. When a connection is made, and when bytes are sent, the workload sill simply\nreturn back to the caller whatever was sent to it adding \"you sent me: \" to the payload. It's not much, but it's a demo after all. The\nsecond service provided is a scrape target for Prometheus. There is one metric exposed by ",(0,o.kt)("inlineCode",{parentName:"p"},"reflectz")," we will care about, the total number of connections established to this workload. This pod also needs an identity provisioned, and this time around we will also provision some services. We will also use the ",(0,o.kt)("inlineCode",{parentName:"p"},"ziti")," cli to enroll this identity. This helm chart wants you to provide an enrolled identity as part of the helm command. Let's do all this now."),(0,o.kt)("h4",{id:"create-and-enroll-the-identity"},"Create and Enroll the Identity"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},"ziti edge create identity user kubeA.reflect.id -o /tmp/prometheus/kubeA.reflect.id.jwt\nziti edge enroll /tmp/prometheus/kubeA.reflect.id.jwt -o /tmp/prometheus/kubeA.reflect.id.json\n")),(0,o.kt)("h4",{id:"create-configs-and-services-including-tunneling-based-access"},"Create Configs and Services (including Tunneling-based Access)"),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"reflectz")," chart also needs two services to be declared and specified at the time of the helm chart installation. We will want to be\nable to test the service to ensure they work. To enable testing the services, we will create two configs of type ",(0,o.kt)("inlineCode",{parentName:"p"},"intercept.v1"),". This\nwill allow identities using tunneling apps to be able to access the services, this is how we'll verify the services work. Make the\nconfigs and services now."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},'# create intercept configs for the two services\nziti edge create config kubeA.reflect.svc-intercept.v1 intercept.v1 \\\n  \'{"protocols":["tcp"],"addresses":["kubeA.reflect.svc.ziti"],"portRanges":[{"low":80, "high":80}]}\'\nziti edge create config "kubeA.reflect.svc-intercept.v1.scrape" intercept.v1 \\\n  \'{"protocols":["tcp"],"addresses":["kubeA.reflect.scrape.svc.ziti"], "portRanges":[{"low":80, "high":80}], "dialOptions":{"identity":"kubeA.reflect.id"}}\'\n\n# create the two services\nziti edge create service "kubeA.reflect.svc" --configs "kubeA.reflect.svc-intercept.v1" -a "kubeA.reflect.svc.services"\nziti edge create service "kubeA.reflect.scrape.svc" --configs "kubeA.reflect.svc-intercept.v1.scrape"\n')),(0,o.kt)("h4",{id:"authorize-the-workload-and-clients"},"Authorize the Workload and Clients"),(0,o.kt)("p",null,"Services are not valuable if there are no identities which can use the services. The identity used in the helm installation will also\nneed to be authorized to bind these services. Tunneling apps will need to be authorized to dial these services but also remember\nPrometheus servers will need to be able to dial these services too. We will now create ",(0,o.kt)("inlineCode",{parentName:"p"},"service-policies")," to authorize the tunneling\nclients, Prometheus scrapes, and the ",(0,o.kt)("inlineCode",{parentName:"p"},"reflectz")," server to bind the service."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},'# create the bind service policies and authorize the reflect id to bind these services\nziti edge create service-policy "kubeA.reflect.svc.bind" Bind \\\n  --service-roles "@kubeA.reflect.svc" --identity-roles "@kubeA.reflect.id"\nziti edge create service-policy "kubeA.reflect.scrape.svc.bind" Bind \\\n  --service-roles "@kubeA.reflect.scrape.svc" --identity-roles "@kubeA.reflect.id"\n\n# create the dial service policies and authorize the reflect id to bind these services\nziti edge create service-policy "kubeA.reflect.svc.dial" Dial \\\n  --service-roles "@kubeA.reflect.svc" --identity-roles "#reflectz-clients"\nziti edge create service-policy "kubeA.reflect.svc.dial.scrape" Dial \\\n  --service-roles "@kubeA.reflect.scrape.svc" --identity-roles "#reflectz-clients"\n')),(0,o.kt)("h4",{id:"deploy-reflectz"},"Deploy ",(0,o.kt)("inlineCode",{parentName:"h4"},"reflectz")),(0,o.kt)("p",null,"With the identity enrolled, we can now install the helm chart from openziti, and install our demonstration workload: ",(0,o.kt)("inlineCode",{parentName:"p"},"reflectz"),". Notice\nthat to deploy ",(0,o.kt)("inlineCode",{parentName:"p"},"reflectz")," we need to supply an identity to the workload using ",(0,o.kt)("inlineCode",{parentName:"p"},"--set-file reflectIdentity"),". This identity will be used\nto 'Bind' the services the workload exposes. We also need to define what the service names are we want to allow that identity to bind.\nWe do this using the ",(0,o.kt)("inlineCode",{parentName:"p"},"--set serviceName")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"--set prometheusServiceName")," flags."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},'helm repo add openziti-test-kitchen https://openziti-test-kitchen.github.io/helm-charts/\nhelm repo update\nhelm install reflectz openziti-test-kitchen/reflect \\\n  --set-file reflectIdentity="/tmp/prometheus/kubeA.reflect.id.json" \\\n  --set serviceName="kubeA.reflect.svc" \\\n  --set prometheusServiceName="kubeA.reflect.scrape.svc"\n')),(0,o.kt)("p",null,"After running helm, pod 2 should be up and running. Let's take a look using ",(0,o.kt)("inlineCode",{parentName:"p"},"kubectl")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},"kubectl get pods\nNAME                        READY   STATUS    RESTARTS   AGE\nreflectz-775bd45d86-4sjwh   1/1     Running   0          7s\nziti-host-db55b5c4b-rpc7f   1/1     Running   0          4m\n")),(0,o.kt)("h3",{id:"pod-3---prometheuz"},"Pod 3 - ",(0,o.kt)("inlineCode",{parentName:"h3"},"Prometheuz")),(0,o.kt)("h4",{id:"overlay-work---setting-up-openziti"},"Overlay Work - Setting Up OpenZiti"),(0,o.kt)("p",null,"Now we have access to the cluster and a workload to monitor. Now we want to deploy Prometheus and monitor this workload. Remember that\nthe workload only exposes a scrape target over the OpenZiti overlay. For Prometheus to be able to scrape the workload, even when\nresident inside the Kubernetes cluster (!), Prometheus will need to be OpenZiti-enabled. That will require a few things. We'll need a\nnew identity for Prometheus, we'll need to authorize Prometheus to access the workload's target, and we'll need to configure Prometheus\nto scrape that workload. When we create this identity we'll assign two attributes. The ",(0,o.kt)("inlineCode",{parentName:"p"},"reflectz-clients")," attribute gives this identity\nthe ability to dial the two services defined above. The ",(0,o.kt)("inlineCode",{parentName:"p"},"prometheus-clients")," attribute is currently unused. We'll put that to use later,\nbut we can define it now."),(0,o.kt)("h4",{id:"create-and-enroll-the-identity-1"},"Create and Enroll the Identity"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},'# create and enroll the identity.\nziti edge create identity user kubeA.prometheus.id -o /tmp/prometheus/kubeA.prometheus.id.jwt -a "reflectz-clients","prometheus-clients"\nziti edge enroll /tmp/prometheus/kubeA.prometheus.id.jwt -o /tmp/prometheus/kubeA.prometheus.id.json\n')),(0,o.kt)("h4",{id:"create-configs-and-services-including-tunneling-based-access-1"},"Create Configs and Services (including Tunneling-based Access)"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},'# create the config and service for the kubeA prometheus server\nziti edge create config "kubeA.prometheus.svc-intercept.v1" intercept.v1 \\\n  \'{"protocols":["tcp"],"addresses":["kubeA.prometheus.svc"],"portRanges":[{"low":80, "high":80}]}\'\nziti edge create config "kubeA.prometheus.svc-host.v1" host.v1 \\\n  \'{"protocol":"tcp", "address":"prometheuz-prometheus-server","port":80}\'\nziti edge create service "kubeA.prometheus.svc" \\\n  --configs "kubeA.prometheus.svc-intercept.v1","kubeA.prometheus.svc-host.v1"\n')),(0,o.kt)("h4",{id:"authorize-the-workload-and-clients-1"},"Authorize the Workload and Clients"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},'# grant the prometheus clients the ability to dial the service and the kubeA.prometheus.id the ability to bind\nziti edge create service-policy "kubeA.prometheus.svc.dial" Dial \\\n  --service-roles "@kubeA.prometheus.svc" \\\n  --identity-roles "#prometheus-clients"\nziti edge create service-policy "kubeA.prometheus.svc.bind" Bind \\\n  --service-roles "@kubeA.prometheus.svc" \\\n  --identity-roles "@kubeA.ziti.id"\n')),(0,o.kt)("h4",{id:"deploying-prometheuz-1"},"Deploying ",(0,o.kt)("inlineCode",{parentName:"h4"},"Prometheuz")),(0,o.kt)("p",null,"With our services, configs and service-policies in place we are now ready to start our Prometheus server. Remember this server will not\nlisten on a the OpenZiti overlay. It's going to listen exclusively on the underlay. We are still exploring OpenZiti, and we are not yet\ncomfortable deploying our Prometheus server dark. We'll change this soon, don't worry. For now, we'll imagine that we're still\nevaluating the tech and chose to deploy it on the underlay, not on the overlay. "),(0,o.kt)("p",null,"Although Prometheus is listening on the underlay, we ",(0,o.kt)("strong",{parentName:"p"},"have")," deployed our workload listening on the overlay network. It won't be\navailable on the underlay at all. The workload has ",(0,o.kt)("strong",{parentName:"p"},"no listening ports"),". This means that we'll still need an OpenZiti-enabled\nPrometheus to access and scrape that workload. To do this we'll use helm, and use a chart provided by the OpenZiti charts repo."),(0,o.kt)("p",null,"Some interesting things to notice below in the ",(0,o.kt)("inlineCode",{parentName:"p"},"helm install")," command. Notice that we are passing helm two ",(0,o.kt)("inlineCode",{parentName:"p"},"--set"),' parameters. These\nparameters are informing the helm chart that the Prometheus server is not "zitified", meaning it will be accessible via the underlay\nnetwork. We\'re also passing one ',(0,o.kt)("inlineCode",{parentName:"p"},"--set-file")," parameter to tell Prometheus what identity we want to be stored in the pod (as a secret).\nThis secret will be used when we configure Prometheus to scrape the workload. Go ahead and run this command now and run\n",(0,o.kt)("inlineCode",{parentName:"p"},"kubectl get pods")," until all the containers are running."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},'helm repo add openziti-test-kitchen https://openziti-test-kitchen.github.io/helm-charts/\nhelm repo update\nhelm install prometheuz openziti-test-kitchen/prometheus \\\n  --set server.ziti.enabled="false" \\\n  --set-file server.scrape.id.contents="/tmp/prometheus/kubeA.prometheus.id.json"\n')),(0,o.kt)("hr",null),(0,o.kt)("h2",{id:"clusterb---fully-dark"},"ClusterB - Fully Dark"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"clusterB",src:i(3969).Z,width:"349",height:"447"})),(0,o.kt)("p",null,"Now that we have deployed our first Kubernetes cluster, it's now time to deploy the second Kubernetes cluster. This time, we are going\nto keep our entire deployment ",(0,o.kt)("strong",{parentName:"p"},"fully dark"),"! There will be no listening ports, not even local to the Kubernetes cluster itself. To get\nany traffic to this Prometheus server, you will need a strong identity and need to be authorized on the OpenZiti overlay. When complete,\nClusterB will look like the image to the right."),(0,o.kt)("p",null,'This time, "Pod1" will be the ',(0,o.kt)("inlineCode",{parentName:"p"},"reflectz")," workload. Since this is a ",(0,o.kt)("strong",{parentName:"p"},"fully dark")," deployment, listening entirely on the OpenZiti overlay,\nwe won't need a ",(0,o.kt)("inlineCode",{parentName:"p"},"ziti-host")," pod. Remember, in ClusterA ",(0,o.kt)("inlineCode",{parentName:"p"},"ziti-host")," is used to provide internal access to the Kubernetes cluster via the\nOpenZiti overlay. It's similar in role to an ingress controller, but doesn't require you to expose your workloads to the internet. While\nthat's pretty good we want to go fully dark this time. We'll have no ",(0,o.kt)("inlineCode",{parentName:"p"},"ziti-host"),". We'll only need to deploy two pods: ",(0,o.kt)("inlineCode",{parentName:"p"},"reflectz")," and\n",(0,o.kt)("inlineCode",{parentName:"p"},"prometheuz"),"."),(0,o.kt)("p",null,'The good news is that the same commands you\'ve run for ClusterA, will mostly be used for ClusterB. You will want to beware that where\nyou used "kubeA" before, make sure you change those to "kubeB". There will be small other changes we\'ll make along the way too, we\'ll see\nthose changes and explain them below. '),(0,o.kt)("h3",{id:"pod1---reflectz"},"Pod1 - ",(0,o.kt)("inlineCode",{parentName:"h3"},"reflectz")),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"relectz")," workload we'll deploy for ClusterB will be nearly identical to the ClusterA workload. We will create a service for\nthe actual 'reflect' service. We will make a service for Prometheus to scrape the workload. We'll also need another identity, so\nwe'll create that identity, authorize it to bind the services, and authorize clients to access the workload. Since this process is very\nsimilar to what we did for ClusterA, there's not much to explain. Setup ClusterB's ",(0,o.kt)("inlineCode",{parentName:"p"},"reflectz")," now."),(0,o.kt)("h4",{id:"create-the-identity-1"},"Create the Identity"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},"ziti edge create identity user kubeB.reflect.id -o /tmp/prometheus/kubeB.reflect.id.jwt\nziti edge enroll /tmp/prometheus/kubeB.reflect.id.jwt -o /tmp/prometheus/kubeB.reflect.id.json\n")),(0,o.kt)("h4",{id:"create-configs-and-services-including-tunneling-based-access-2"},"Create Configs and Services (including Tunneling-based Access)"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},'# create intercept configs for the two services\nziti edge create config kubeB.reflect.svc-intercept.v1 intercept.v1 \\\n  \'{"protocols":["tcp"],"addresses":["kubeB.reflect.svc.ziti"],"portRanges":[{"low":80, "high":80}]}\'\nziti edge create config "kubeB.reflect.svc-intercept.v1.scrape" intercept.v1 \\\n  \'{"protocols":["tcp"],"addresses":["kubeB.reflect.scrape.svc.ziti"], "portRanges":[{"low":80, "high":80}], "dialOptions":{"identity":"kubeB.reflect.id"}}\'\n\n# create the two services\nziti edge create service "kubeB.reflect.svc" --configs "kubeB.reflect.svc-intercept.v1" -a "kubeB.reflect.svc.services"\nziti edge create service "kubeB.reflect.scrape.svc" --configs "kubeB.reflect.svc-intercept.v1.scrape"\n')),(0,o.kt)("h4",{id:"authorize-the-workload-to-bind-the-services"},"Authorize the Workload to Bind the Services"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},'# create the bind service policies and authorize the reflect id to bind these services\nziti edge create service-policy "kubeB.reflect.svc.bind" Bind \\\n  --service-roles "@kubeB.reflect.svc" --identity-roles "@kubeB.reflect.id"\nziti edge create service-policy "kubeB.reflect.scrape.svc.bind" Bind \\\n  --service-roles "@kubeB.reflect.scrape.svc" --identity-roles "@kubeB.reflect.id"\n')),(0,o.kt)("h4",{id:"authorize-clients-to-access-the-services"},"Authorize Clients to Access the Services"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},'# create the dial service policies and authorize the reflect id to bind these services\nziti edge create service-policy "kubeB.reflect.svc.dial" Dial \\\n  --service-roles "@kubeB.reflect.svc" --identity-roles "#reflectz-clients"\nziti edge create service-policy "kubeB.reflect.svc.dial.scrape" Dial \\\n  --service-roles "@kubeB.reflect.scrape.svc" --identity-roles "#reflectz-clients"\n')),(0,o.kt)("h4",{id:"deploy-reflectz-1"},"Deploy ",(0,o.kt)("inlineCode",{parentName:"h4"},"reflectz")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},'helm repo add openziti-test-kitchen https://openziti-test-kitchen.github.io/helm-charts/\nhelm repo update\nhelm install reflectz openziti-test-kitchen/reflect \\\n  --set-file reflectIdentity="/tmp/prometheus/kubeB.reflect.id.json" \\\n  --set serviceName="kubeB.reflect.svc" \\\n  --set prometheusServiceName="kubeB.reflect.scrape.svc"\n')),(0,o.kt)("h3",{id:"pod-2---prometheuz"},"Pod 2 - ",(0,o.kt)("inlineCode",{parentName:"h3"},"Prometheuz")),(0,o.kt)("p",null,"For ClusterB we want ",(0,o.kt)("inlineCode",{parentName:"p"},"Prometheuz")," to be ",(0,o.kt)("strong",{parentName:"p"},"totally dark"),". It will exclusively listen on the OpenZiti overlay and there will be no\nlistening ports on the underlay. We will need another identity, of course, and most of the configuration and commands appear the same on\nthe surface with very subtle differences. We'll explore these differences as we go. In this section we'll be making an identity, ",(0,o.kt)("strong",{parentName:"p"},"one\nconfig")," (a difference from the ClusterA install), a service, and two service-policies. Let's get to it."),(0,o.kt)("h4",{id:"create-the-identity-2"},"Create the Identity"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},'ziti edge create identity user kubeB.prometheus.id -o /tmp/prometheus/kubeB.prometheus.id.jwt -a "reflectz-clients","prometheus-clients"\nziti edge enroll /tmp/prometheus/kubeB.prometheus.id.jwt -o /tmp/prometheus/kubeB.prometheus.id.json\n')),(0,o.kt)("h4",{id:"create-one-config-and-service"},"Create ",(0,o.kt)("strong",{parentName:"h4"},"One")," Config and Service"),(0,o.kt)("p",null,"Here's a difference from ClusterA. Since we are going to listen on the OpenZiti overlay, we are not installing ",(0,o.kt)("inlineCode",{parentName:"p"},"ziti-host"),". That means\nwe don't need to create a ",(0,o.kt)("inlineCode",{parentName:"p"},"host.v1")," config. A ",(0,o.kt)("inlineCode",{parentName:"p"},"host.v1")," config is necessary for services which have a 'Bind' configuration and are being\nbound by a tunneling application. We're not doing that, here Prometheus will 'Bind' this service, thus we don't need that ",(0,o.kt)("inlineCode",{parentName:"p"},"host.v1"),"\nconfig."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},'# create the config and service for the kubeB prometheus server\nziti edge create config "kubeB.prometheus.svc-intercept.v1" intercept.v1 \\\n  \'{"protocols":["tcp"],"addresses":["kubeB.prometheus.svc"],"portRanges":[{"low":80, "high":80}], "dialOptions": {"identity":"kubeB.prometheus.id"}}\'\n# no need for the host.v1 config\nziti edge create service "kubeB.prometheus.svc" \\\n  --configs "kubeB.prometheus.svc-intercept.v1"\n')),(0,o.kt)("h4",{id:"authorize-clients-and-prometheus-to-bind-the-service"},"Authorize Clients and Prometheus to Bind the Service"),(0,o.kt)("p",null,'At first, these commands appear identical. You need to look very closely to notice the difference between these command and the ones we\nran for ClusterA, other than the obvious changes from "kubeA" to "kubeB". Pay close attention to the supplied ',(0,o.kt)("inlineCode",{parentName:"p"},"--identity-roles")," for the\nbind policy specified below. With ClusterA, we did not have Prometheus listen on the overlay and we allowed Prometheus to listen on the\nunderlay. That meant we needed to deploy ",(0,o.kt)("inlineCode",{parentName:"p"},"ziti-host")," into that cluster to provide access to the service, and that means the service had\nto be bound by the ",(0,o.kt)("inlineCode",{parentName:"p"},"ziti-host")," identity."),(0,o.kt)("p",null,"Here we are flipping that script. We are allowing Prometheus to bind this service! That means we'll need to authorize the\n",(0,o.kt)("inlineCode",{parentName:"p"},"kubeB.prometheus.id")," to be able to bind the service."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},'# grant the prometheus clients the ability to dial the service and the kubeB.prometheus.id the ability to bind\nziti edge create service-policy "kubeB.prometheus.svc.dial" Dial \\\n  --service-roles "@kubeB.prometheus.svc" \\\n  --identity-roles "#prometheus-clients"\nziti edge create service-policy "kubeB.prometheus.svc.bind" Bind \\\n  --service-roles "@kubeB.prometheus.svc" \\\n  --identity-roles "@kubeB.prometheus.id"\n')),(0,o.kt)("h4",{id:"deploying-prometheuz"},"Deploying ",(0,o.kt)("inlineCode",{parentName:"h4"},"Prometheuz")),(0,o.kt)("p",null,"At this point we have the OpenZiti overlay all configured. What's left, is to deploy Prometheus into ClusterB. This command is substantially\ndifferent from what we ran while deploying Prometheus into ClusterA. You'll see that we need to supply two other identities for this\ninstallation. Remember, Prometheus will be entirely dark once deployed into ClusterB, listening only on the OpenZiti overlay. The container\nin the pod which monitors configmap changes won't be able to trigger a webhook using the underlay! This ",(0,o.kt)("inlineCode",{parentName:"p"},"configmap-reloadz"),' is a second\n"zitification" we didn\'t realize we were deploying in ClusterA, because we did not need it. We need it for ClusterB.'),(0,o.kt)("p",null,"You'll see for configmapReload we need to supply the identity which the container will use to hit the Prometheus webhook. We do that by\npassing ",(0,o.kt)("inlineCode",{parentName:"p"},'--set-file configmapReload.ziti.id.contents="/tmp/prometheus/kubeB.prometheus.id.json"'),". Then we'll supply the service which\n",(0,o.kt)("inlineCode",{parentName:"p"},"configmap-reloadz")," will dial, and we'll also specify what identity we expect to be hosting the service."),(0,o.kt)("p",null,"Next you'll see we need to supply the identity to the Prometheus server we want to allow to listen on the OpenZiti overlay (\n",(0,o.kt)("inlineCode",{parentName:"p"},"-set-file server.ziti.id.contents"),"). Similar to ",(0,o.kt)("inlineCode",{parentName:"p"},"configmap-reloadz")," we will also specify the service and identity name to bind."),(0,o.kt)("p",null,"Finally, to allow the server to scrape targets we need to supply a final identity which will be used when scraping targets with\n",(0,o.kt)("inlineCode",{parentName:"p"},"--set-file server.scrape.id.contents"),"."),(0,o.kt)("p",null,"You'll notice for simplicities sake, we are using the same identity for all three needs which is perfectly fine. If you wanted to use a\ndifferent identity, you could. That choice is up to you. To keep it simple we just authorized this identity for all these purposes."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},'# install prometheus\nhelm repo add openziti-test-kitchen https://openziti-test-kitchen.github.io/helm-charts/\nhelm repo update\nhelm install prometheuz openziti-test-kitchen/prometheus \\\n  --set-file configmapReload.ziti.id.contents="/tmp/prometheus/kubeB.prometheus.id.json" \\\n       --set configmapReload.ziti.targetService="kubeB.prometheus.svc" \\\n       --set configmapReload.ziti.targetIdentity="kubeB.prometheus.id" \\\n  --set-file server.ziti.id.contents="/tmp/prometheus/kubeB.prometheus.id.json" \\\n       --set server.ziti.service="kubeB.prometheus.svc" \\\n       --set server.ziti.identity="kubeB.prometheus.id" \\\n  --set-file server.scrape.id.contents="/tmp/prometheus/kubeB.prometheus.id.json"\n')),(0,o.kt)("h2",{id:"whats-next"},"What's Next"),(0,o.kt)("p",null,"In this article we've done a lot of OpenZiti CLI work, run some ",(0,o.kt)("inlineCode",{parentName:"p"},"kubectl")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"helm")," commands but we still haven't explored what it is\nwe are building and why it's so cool. We'll do that in the ",(0,o.kt)("a",{parentName:"p",href:"/blog/zitification/prometheus/part3"},"last, and final")," article. Hopefully, the payoff for you will be\nas rewarding as it was for me while building this article series."),(0,o.kt)("hr",null),(0,o.kt)("h4",{id:"addendum---a-quicker-start"},"Addendum - a Quicker Start"),(0,o.kt)("p",null,"All the commands above are also available in github as ",(0,o.kt)("inlineCode",{parentName:"p"},".sh")," scripts. If you would prefer, you can clone the\n",(0,o.kt)("a",{parentName:"p",href:"https://github.com/openziti/ziti-doc"},"ziti-doc repository"),' and access the scripts from the path mentioned below. "Cleanup" scripts are\nprovided if desired. '),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},"${checkout_root}/docusaurus/blog/zitification/prometheus/scripts\n")))}p.isMDXComponent=!0},13:(e,t,i)=>{i.d(t,{Z:()=>n});const n=i.p+"assets/images/clusterA-71f957b6205e44af29d35d4d65efc06b.svg"},3969:(e,t,i)=>{i.d(t,{Z:()=>n});const n=i.p+"assets/images/clusterB-9e8019e9f78c665bd67f52585250b986.svg"},81283:(e,t,i)=>{i.d(t,{Z:()=>n});const n=i.p+"assets/images/kubernetes-prometheus-after-1c432161cd5ceac47eadc4149cae35fb.svg"}}]);